{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1916045-3de4-4782-9bca-3b7c30a66d43",
   "metadata": {
    "id": "b1916045-3de4-4782-9bca-3b7c30a66d43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 10:21:25.843086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-31 10:21:25.843128: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25061e1e-7778-4f20-974b-7b691a2df20b",
   "metadata": {
    "id": "25061e1e-7778-4f20-974b-7b691a2df20b"
   },
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(\n",
    "    origin=\"http://mireu-server.iptime.org:8000/list/HDD1/hana/Garbage_Images.tar.gz\",\n",
    "    fname=\"Garbage_Images\",\n",
    "    untar=True\n",
    ")\n",
    "\n",
    "img_list = pathlib.Path(data_dir)\n",
    "image_count = len(list(img_list.glob('*/*.jpg')))\n",
    "images_categories = ['metal', 'glass', 'paper', 'trash', 'cardboard', 'plastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321629a-cce6-49ff-a163-a76e8b153032",
   "metadata": {
    "id": "7321629a-cce6-49ff-a163-a76e8b153032"
   },
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(512, 384),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(512, 384),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f8ae6-ebdc-4480-8815-5fd7559cec95",
   "metadata": {
    "id": "5f2f8ae6-ebdc-4480-8815-5fd7559cec95"
   },
   "outputs": [],
   "source": [
    "def ai_models():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(512, 384, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "        tf.keras.layers.Dense(len(images_categories), activation='softmax')\n",
    "    ])\n",
    "    # model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['acc'])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec19bc-bff7-4b7e-8e42-60cb143c06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 모델 객체를 만들고 훈련합니다\n",
    "model = ai_models()\n",
    "\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=50)\n",
    "\n",
    "# SavedModel로 전체 모델을 저장합니다\n",
    "model.save('Data/ai_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e19f6-3549-4394-b6a4-359bbaffc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(cp_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6221a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 10:21:32.869724: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-31 10:21:32.869771: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-31 10:21:32.869802: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HOSTING): /proc/driver/nvidia/version does not exist\n",
      "2022-03-31 10:21:32.870086: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 512, 384, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 256, 192, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 192, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 128, 96, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 96, 32)       18464     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 64, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 48, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24576)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1572928   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,620,422\n",
      "Trainable params: 1,620,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "com_models = tf.keras.models.load_model('Data/ai_models')\n",
    "\n",
    "com_models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_models.evaluate(validation_generator, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e830b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=tf.keras.preprocessing.image.load_img(\"1.png\", target_size=(512, 384))\n",
    "\n",
    "x=tf.keras.preprocessing.image.img_to_array(img)\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = com_models.predict(images, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7760fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "{'glass': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(classes[0][5])\n",
    "images_categories = ['metal', 'glass', 'paper', 'trash', 'cardboard', 'plastic']\n",
    "\n",
    "a = 0\n",
    "for images_categorie in images_categories:\n",
    "    # print(classes[0][a], images_categorie)\n",
    "    if classes[0][a] == 1:\n",
    "        # return classes[0]\n",
    "        print({images_categorie:classes[0][a]})\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b843e8-1d08-4b14-9747-5a57e9555ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array:\n",
      "[2 6 1 5]\n",
      "\n",
      "Index with the largest value:\n",
      "1\n",
      "\n",
      "The largest value in the array:\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "a=np.array([2,6,1,5])\n",
    "\n",
    "print(\"Array:\")\n",
    "print(a)\n",
    "\n",
    "req_index=np.argmax(a)\n",
    "print(\"\\nIndex with the largest value:\")\n",
    "print(req_index)\n",
    "\n",
    "print(\"\\nThe largest value in the array:\")\n",
    "print(a[req_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc2cf5-3283-48cd-8893-31e3fe690ef5",
   "metadata": {
    "id": "40fc2cf5-3283-48cd-8893-31e3fe690ef5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "pyplot.figure(figsize=(18, 6))\n",
    "\n",
    "# 에포크별 정확도\n",
    "pyplot.subplot(1,2,1)\n",
    "pyplot.plot(com_models.history[\"acc\"], label=\"accuracy\")\n",
    "pyplot.plot(com_models.history[\"val_acc\"], label=\"val_accuracy\")\n",
    "pyplot.title(\"accuracy\")\n",
    "pyplot.legend()\n",
    "\n",
    "# 에포크별 손실률\n",
    "pyplot.subplot(1,2,2)\n",
    "pyplot.plot(com_models.history[\"loss\"], label=\"loss\")\n",
    "pyplot.plot(com_models.history[\"val_loss\"], label=\"val_loss\")\n",
    "pyplot.title(\"loss\")\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
