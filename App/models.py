# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JRONhCc2w46eZEmBJkwGk5BcqdJSa5am
"""

import numpy as np
import tensorflow as tf
import pathlib

data_dir = tf.keras.utils.get_file(
    origin="http://mireu-server.iptime.org:8000/list/HDD2/hana/Garbage_images.tar.gz",
    fname="Garbage_images",
    untar=True
)

img_list = pathlib.Path(data_dir)
image_count = len(list(img_list.glob('*/*.jpg')))
images_categories = ['metal', 'glass', 'paper', 'trash', 'cardboard', 'plastic']

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    vertical_flip=True,
    validation_split=0.1
)

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    validation_split=0.1
)

train_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=(512, 384),
    batch_size=16,
    class_mode='categorical',
    subset='training',
    seed=0
)

validation_generator = test_datagen.flow_from_directory(
    data_dir,
    target_size=(512, 384),
    batch_size=16,
    class_mode='categorical',
    subset='validation',
    seed=0
)

labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(512, 384, 3)),
    tf.keras.layers.MaxPooling2D(pool_size=2),

    tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),

    tf.keras.layers.Flatten(),

    tf.keras.layers.Dense(64, activation='relu'),

    tf.keras.layers.Dense(len(images_categories), activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])

model.fit(train_generator, epochs=50, validation_data=validation_generator)

def model_run_main(file_path):
    img=image.load_img(file_path, target_size=(100, 100))

    x=image.img_to_array(img)
    x=np.expand_dims(x, axis=0)
    images = np.vstack([x])

    classes = model.predict(images, batch_size=10)

    print(classes[0])

    a = 0
    for images_categorie in images_categories:
        # print(classes[0][a], images_categorie)

        if classes[0][a] > 0.0:
            print(classes[0][a], images_categorie)
        else:
            pass
        
        a = a + 1
